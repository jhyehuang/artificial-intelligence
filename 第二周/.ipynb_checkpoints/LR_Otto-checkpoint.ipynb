{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic 回归——Otto商品分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们以Kaggle 2015年举办的Otto Group Product Classification Challenge竞赛数据为例，分别调用缺省参数LogisticRegression、LogisticRegression + GridSearchCV以及LogisticRegressionCV进行参数调优。实际应用中LogisticRegression + GridSearchCV或LogisticRegressionCV任选一个即可。\n",
    "\n",
    "Otto数据集是著名电商Otto提供的一个多类商品分类问题，类别数=9. 每个样本有93维数值型特征（整数，表示某种事件发生的次数，已经进行过脱敏处理）。 竞赛官网：https://www.kaggle.com/c/otto-group-product-classification-challenge/data\n",
    "\n",
    "\n",
    "第一名：https://www.kaggle.com/c/otto-group-product-classification-challenge/discussion/14335\n",
    "第二名：http://blog.kaggle.com/2015/06/09/otto-product-classification-winners-interview-2nd-place-alexander-guschin/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 首先 import 必要的模块\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#竞赛的评价指标为logloss\n",
    "from sklearn.metrics import log_loss  \n",
    "\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据 & 数据探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  feat_9  \\\n",
       "0   1       1       0       0       0       0       0       0       0       0   \n",
       "1   2       0       0       0       0       0       0       0       1       0   \n",
       "2   3       0       0       0       0       0       0       0       1       0   \n",
       "3   4       1       0       0       1       6       1       5       0       0   \n",
       "4   5       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "    ...     feat_85  feat_86  feat_87  feat_88  feat_89  feat_90  feat_91  \\\n",
       "0   ...           1        0        0        0        0        0        0   \n",
       "1   ...           0        0        0        0        0        0        0   \n",
       "2   ...           0        0        0        0        0        0        0   \n",
       "3   ...           0        1        2        0        0        0        0   \n",
       "4   ...           1        0        0        0        0        1        0   \n",
       "\n",
       "   feat_92  feat_93   target  \n",
       "0        0        0  Class_1  \n",
       "1        0        0  Class_1  \n",
       "2        0        0  Class_1  \n",
       "3        0        0  Class_1  \n",
       "4        0        0  Class_1  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取数据\n",
    "# path to where the data lies\n",
    "dpath = './data/'\n",
    "train = pd.read_csv(dpath +\"Otto_train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 61878 entries, 0 to 61877\n",
      "Data columns (total 95 columns):\n",
      "id         61878 non-null int64\n",
      "feat_1     61878 non-null int64\n",
      "feat_2     61878 non-null int64\n",
      "feat_3     61878 non-null int64\n",
      "feat_4     61878 non-null int64\n",
      "feat_5     61878 non-null int64\n",
      "feat_6     61878 non-null int64\n",
      "feat_7     61878 non-null int64\n",
      "feat_8     61878 non-null int64\n",
      "feat_9     61878 non-null int64\n",
      "feat_10    61878 non-null int64\n",
      "feat_11    61878 non-null int64\n",
      "feat_12    61878 non-null int64\n",
      "feat_13    61878 non-null int64\n",
      "feat_14    61878 non-null int64\n",
      "feat_15    61878 non-null int64\n",
      "feat_16    61878 non-null int64\n",
      "feat_17    61878 non-null int64\n",
      "feat_18    61878 non-null int64\n",
      "feat_19    61878 non-null int64\n",
      "feat_20    61878 non-null int64\n",
      "feat_21    61878 non-null int64\n",
      "feat_22    61878 non-null int64\n",
      "feat_23    61878 non-null int64\n",
      "feat_24    61878 non-null int64\n",
      "feat_25    61878 non-null int64\n",
      "feat_26    61878 non-null int64\n",
      "feat_27    61878 non-null int64\n",
      "feat_28    61878 non-null int64\n",
      "feat_29    61878 non-null int64\n",
      "feat_30    61878 non-null int64\n",
      "feat_31    61878 non-null int64\n",
      "feat_32    61878 non-null int64\n",
      "feat_33    61878 non-null int64\n",
      "feat_34    61878 non-null int64\n",
      "feat_35    61878 non-null int64\n",
      "feat_36    61878 non-null int64\n",
      "feat_37    61878 non-null int64\n",
      "feat_38    61878 non-null int64\n",
      "feat_39    61878 non-null int64\n",
      "feat_40    61878 non-null int64\n",
      "feat_41    61878 non-null int64\n",
      "feat_42    61878 non-null int64\n",
      "feat_43    61878 non-null int64\n",
      "feat_44    61878 non-null int64\n",
      "feat_45    61878 non-null int64\n",
      "feat_46    61878 non-null int64\n",
      "feat_47    61878 non-null int64\n",
      "feat_48    61878 non-null int64\n",
      "feat_49    61878 non-null int64\n",
      "feat_50    61878 non-null int64\n",
      "feat_51    61878 non-null int64\n",
      "feat_52    61878 non-null int64\n",
      "feat_53    61878 non-null int64\n",
      "feat_54    61878 non-null int64\n",
      "feat_55    61878 non-null int64\n",
      "feat_56    61878 non-null int64\n",
      "feat_57    61878 non-null int64\n",
      "feat_58    61878 non-null int64\n",
      "feat_59    61878 non-null int64\n",
      "feat_60    61878 non-null int64\n",
      "feat_61    61878 non-null int64\n",
      "feat_62    61878 non-null int64\n",
      "feat_63    61878 non-null int64\n",
      "feat_64    61878 non-null int64\n",
      "feat_65    61878 non-null int64\n",
      "feat_66    61878 non-null int64\n",
      "feat_67    61878 non-null int64\n",
      "feat_68    61878 non-null int64\n",
      "feat_69    61878 non-null int64\n",
      "feat_70    61878 non-null int64\n",
      "feat_71    61878 non-null int64\n",
      "feat_72    61878 non-null int64\n",
      "feat_73    61878 non-null int64\n",
      "feat_74    61878 non-null int64\n",
      "feat_75    61878 non-null int64\n",
      "feat_76    61878 non-null int64\n",
      "feat_77    61878 non-null int64\n",
      "feat_78    61878 non-null int64\n",
      "feat_79    61878 non-null int64\n",
      "feat_80    61878 non-null int64\n",
      "feat_81    61878 non-null int64\n",
      "feat_82    61878 non-null int64\n",
      "feat_83    61878 non-null int64\n",
      "feat_84    61878 non-null int64\n",
      "feat_85    61878 non-null int64\n",
      "feat_86    61878 non-null int64\n",
      "feat_87    61878 non-null int64\n",
      "feat_88    61878 non-null int64\n",
      "feat_89    61878 non-null int64\n",
      "feat_90    61878 non-null int64\n",
      "feat_91    61878 non-null int64\n",
      "feat_92    61878 non-null int64\n",
      "feat_93    61878 non-null int64\n",
      "target     61878 non-null object\n",
      "dtypes: int64(94), object(1)\n",
      "memory usage: 44.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_84</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.00000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30939.500000</td>\n",
       "      <td>0.38668</td>\n",
       "      <td>0.263066</td>\n",
       "      <td>0.901467</td>\n",
       "      <td>0.779081</td>\n",
       "      <td>0.071043</td>\n",
       "      <td>0.025696</td>\n",
       "      <td>0.193704</td>\n",
       "      <td>0.662433</td>\n",
       "      <td>1.011296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070752</td>\n",
       "      <td>0.532306</td>\n",
       "      <td>1.128576</td>\n",
       "      <td>0.393549</td>\n",
       "      <td>0.874915</td>\n",
       "      <td>0.457772</td>\n",
       "      <td>0.812421</td>\n",
       "      <td>0.264941</td>\n",
       "      <td>0.380119</td>\n",
       "      <td>0.126135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17862.784315</td>\n",
       "      <td>1.52533</td>\n",
       "      <td>1.252073</td>\n",
       "      <td>2.934818</td>\n",
       "      <td>2.788005</td>\n",
       "      <td>0.438902</td>\n",
       "      <td>0.215333</td>\n",
       "      <td>1.030102</td>\n",
       "      <td>2.255770</td>\n",
       "      <td>3.474822</td>\n",
       "      <td>...</td>\n",
       "      <td>1.151460</td>\n",
       "      <td>1.900438</td>\n",
       "      <td>2.681554</td>\n",
       "      <td>1.575455</td>\n",
       "      <td>2.115466</td>\n",
       "      <td>1.527385</td>\n",
       "      <td>4.597804</td>\n",
       "      <td>2.045646</td>\n",
       "      <td>0.982385</td>\n",
       "      <td>1.201720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15470.250000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30939.500000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>46408.750000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61.00000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>87.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id       feat_1        feat_2        feat_3        feat_4  \\\n",
       "count  61878.000000  61878.00000  61878.000000  61878.000000  61878.000000   \n",
       "mean   30939.500000      0.38668      0.263066      0.901467      0.779081   \n",
       "std    17862.784315      1.52533      1.252073      2.934818      2.788005   \n",
       "min        1.000000      0.00000      0.000000      0.000000      0.000000   \n",
       "25%    15470.250000      0.00000      0.000000      0.000000      0.000000   \n",
       "50%    30939.500000      0.00000      0.000000      0.000000      0.000000   \n",
       "75%    46408.750000      0.00000      0.000000      0.000000      0.000000   \n",
       "max    61878.000000     61.00000     51.000000     64.000000     70.000000   \n",
       "\n",
       "             feat_5        feat_6        feat_7        feat_8        feat_9  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.071043      0.025696      0.193704      0.662433      1.011296   \n",
       "std        0.438902      0.215333      1.030102      2.255770      3.474822   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      1.000000      0.000000   \n",
       "max       19.000000     10.000000     38.000000     76.000000     43.000000   \n",
       "\n",
       "           ...            feat_84       feat_85       feat_86       feat_87  \\\n",
       "count      ...       61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       ...           0.070752      0.532306      1.128576      0.393549   \n",
       "std        ...           1.151460      1.900438      2.681554      1.575455   \n",
       "min        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "25%        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "50%        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "75%        ...           0.000000      0.000000      1.000000      0.000000   \n",
       "max        ...          76.000000     55.000000     65.000000     67.000000   \n",
       "\n",
       "            feat_88       feat_89       feat_90       feat_91       feat_92  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.874915      0.457772      0.812421      0.264941      0.380119   \n",
       "std        2.115466      1.527385      4.597804      2.045646      0.982385   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       30.000000     61.000000    130.000000     52.000000     19.000000   \n",
       "\n",
       "            feat_93  \n",
       "count  61878.000000  \n",
       "mean       0.126135  \n",
       "std        1.201720  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max       87.000000  \n",
       "\n",
       "[8 rows x 94 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 各属性的统计特性\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAELCAYAAAARNxsIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f5b2032c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Target 分布，看看各类样本分布是否均衡\n",
    "sns.countplot(train.target);\n",
    "pyplot.xlabel('target');\n",
    "pyplot.ylabel('Number of occurrences');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各类样本不均衡。交叉验证对分类任务缺省的是采用StratifiedKFold，在每折采样时根据各类样本按比例采样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-ee3a7f4fa25e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#（分类中其实还需要确保取出来的这部分样本各类样本的比例和总体一致）\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mn_trains\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn_trains\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#或者考虑用train_test_split而不是交叉验证来验证模型性能\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3081\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3083\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'label'"
     ]
    }
   ],
   "source": [
    "# 将类别字符串变成数字\n",
    "# drop ids and get labels\n",
    "y_train = train['target']   #形式为Class_x\n",
    "y_train = y_train.map(lambda s: s[6:])\n",
    "y_train = y_train.map(lambda s: int(s)-1)\n",
    "\n",
    "train = train.drop([\"id\", \"target\"], axis=1)\n",
    "X_train = np.array(train)\n",
    "\n",
    "#如果计算资源有限，也可只取少量样本，如取前1000个样本\n",
    "#（分类中其实还需要确保取出来的这部分样本各类样本的比例和总体一致）\n",
    "n_trains = 1000\n",
    "y_train = train.target.values[:n_trains]\n",
    "\n",
    "#或者考虑用train_test_split而不是交叉验证来验证模型性能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 初始化特征的标准化器\n",
    "ss_X = StandardScaler()\n",
    "\n",
    "# 分别对训练和测试数据的特征进行标准化处理\n",
    "X_train = ss_X.fit_transform(X_train)\n",
    "#X_test = ss_X.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### default Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr= LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 交叉验证用于评估模型性能和进行参数调优（模型选择）\n",
    "#分类任务中交叉验证缺省是采用StratifiedKFold\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "loss = cross_val_score(lr, X_train, y_train, cv=5, scoring='neg_log_loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('logloss of each fold is: ',-loss)\n",
    "print ('cv logloss is:', -loss.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正则化的 Logistic Regression及参数调优"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logistic回归的需要调整超参数有：C（正则系数，一般在log域（取log后的值）均匀设置候选参数）和正则函数penalty（L2/L1） \n",
    "目标函数为：J = sum(logloss(f(xi), yi)) + C* penalty \n",
    "\n",
    "在sklearn框架下，不同学习器的参数调整步骤相同：\n",
    "设置候选参数集合\n",
    "调用GridSearchCV\n",
    "调用fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#需要调优的参数\n",
    "# 请尝试将L1正则和L2正则分开，并配合合适的优化求解算法（slover）\n",
    "#tuned_parameters = {'penalty':['l1','l2'],\n",
    "#                   'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "#                   }\n",
    "penaltys = ['l1','l2']\n",
    "Cs = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "tuned_parameters = dict(penalty = penaltys, C = Cs)\n",
    "\n",
    "lr_penalty= LogisticRegression()\n",
    "grid= GridSearchCV(lr_penalty, tuned_parameters,cv=5, scoring='neg_log_loss')\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# view the complete results (list of named tuples)\n",
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# examine the best model\n",
    "print(-grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果最佳值在候选参数的边缘，最好再尝试更大的候选参数或更小的候选参数，直到找到拐点。\n",
    "l2, c=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.DataFrame(grid.cv_results_).to_csv('LogisticGridSearchCV_Otto.csv')\n",
    "#cvresult = pd.DataFrame.from_csv('LogisticGridSearchCV_Otto.csv')\n",
    "#test_means = cv_results['mean_test_score']\n",
    "#test_stds = cv_results['std_test_score'] \n",
    "#train_means = cvresult['mean_train_score']\n",
    "#train_stds = cvresult['std_train_score'] \n",
    "\n",
    "\n",
    "# plot CV误差曲线\n",
    "test_means = grid.cv_results_[ 'mean_test_score' ]\n",
    "test_stds = grid.cv_results_[ 'std_test_score' ]\n",
    "train_means = grid.cv_results_[ 'mean_train_score' ]\n",
    "train_stds = grid.cv_results_[ 'std_train_score' ]\n",
    "\n",
    "\n",
    "# plot results\n",
    "n_Cs = len(Cs)\n",
    "number_penaltys = len(penaltys)\n",
    "test_scores = np.array(test_means).reshape(n_Cs,number_penaltys)\n",
    "train_scores = np.array(train_means).reshape(n_Cs,number_penaltys)\n",
    "test_stds = np.array(test_stds).reshape(n_Cs,number_penaltys)\n",
    "train_stds = np.array(train_stds).reshape(n_Cs,number_penaltys)\n",
    "\n",
    "x_axis = np.log10(Cs)\n",
    "for i, value in enumerate(penaltys):\n",
    "    #pyplot.plot(log(Cs), test_scores[i], label= 'penalty:'   + str(value))\n",
    "    pyplot.errorbar(x_axis, test_scores[:,i], yerr=test_stds[:,i] ,label = penaltys[i] +' Test')\n",
    "    pyplot.errorbar(x_axis, train_scores[:,i], yerr=train_stds[:,i] ,label = penaltys[i] +' Train')\n",
    "    \n",
    "pyplot.legend()\n",
    "pyplot.xlabel( 'log(C)' )                                                                                                      \n",
    "pyplot.ylabel( 'neg-logloss' )\n",
    "pyplot.savefig('LogisticGridSearchCV_C.png' )\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上图给出了L1正则和L2正则下、不同正则参数C对应的模型在训练集上测试集上的正确率（score）。可以看出在训练集上C越大（正则越少）的模型性能越好；但在测试集上当C=100时性能最好（L1正则和L2正则均是）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用LogisticRegressionCV实现正则化的 Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1正则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "Cs = [1, 10,100,1000]\n",
    "\n",
    "# 大量样本（6W+）、高维度（93），L1正则 --> 可选用saga优化求解器(0.19版本新功能)\n",
    "# LogisticRegressionCV比GridSearchCV快\n",
    "lrcv_L1 = LogisticRegressionCV(Cs=Cs, cv = 5, scoring='neg_log_loss', penalty='l1', solver='liblinear', multi_class='ovr')\n",
    "lrcv_L1.fit(X_train, y_train)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lrcv_L1.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scores_：dict with classes as the keys, and the values as the grid of scores obtained during cross-validating each fold,\n",
    "# Each dict value has shape (n_folds, len(Cs))\n",
    "n_Cs = len(Cs)\n",
    "n_classes = 9\n",
    "scores =  np.zeros((n_classes,n_Cs))\n",
    "\n",
    "for j in range(n_classes):\n",
    "        scores[j][:] = np.mean(lrcv_L1.scores_[j],axis = 0)\n",
    "    \n",
    "mse_mean = -np.mean(scores, axis = 0)\n",
    "pyplot.plot(np.log10(Cs), mse_mean.reshape(n_Cs,1)) \n",
    "#plt.plot(np.log10(reg.Cs)*np.ones(3), [0.28, 0.29, 0.30])\n",
    "pyplot.xlabel('log(C)')\n",
    "pyplot.ylabel('neg-logloss')\n",
    "pyplot.show()\n",
    "\n",
    "#print ('C is:',lr_cv.C_)  #对多类分类问题，每个类别的分类器有一个C\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个score似乎和GridSearchCV得到的Score不一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrcv_L1.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "惩罚不够，没有稀疏系数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2正则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "Cs = [1, 10,100,1000]\n",
    "\n",
    "# 大量样本（6W+）、高维度（93），L2正则 --> 缺省用lbfgs，为了和GridSeachCV比较，也用liblinear\n",
    "\n",
    "lr_cv_L2 = LogisticRegressionCV(Cs=Cs, cv = 5, scoring='neg_log_loss', penalty='l2', solver='liblinear', multi_class='ovr')\n",
    "lr_cv_L2.fit(X_train, y_train)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_cv.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dict with classes as the keys, and the values as the grid of scores obtained during cross-validating each fold,\n",
    "# Each dict value has shape (n_folds, len(Cs))\n",
    "n_Cs = len(Cs)\n",
    "n_classes = 9\n",
    "scores =  np.zeros((n_classes,n_Cs))\n",
    "\n",
    "for j in range(n_classes):\n",
    "        scores[j][:] = np.mean(lr_cv.scores_[j],axis = 0)\n",
    "    \n",
    "mse_mean = -np.mean(scores, axis = 0)\n",
    "pyplot.plot(np.log10(Cs), mse_mean.reshape(n_Cs,1)) \n",
    "#plt.plot(np.log10(reg.Cs)*np.ones(3), [0.28, 0.29, 0.30])\n",
    "pyplot.xlabel('log(C)')\n",
    "pyplot.ylabel('neg-logloss')\n",
    "pyplot.show()\n",
    "\n",
    "#print ('C is:',lr_cv.C_)  #对多类分类问题，每个类别的分类器有一个C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "Cs = [1, 10,100,1000]\n",
    "\n",
    "# 大量样本（6W+）、高维度（93），L2正则 --> 缺省用lbfgs\n",
    "# LogisticRegressionCV比GridSearchCV快\n",
    "lrcv_L2 = LogisticRegressionCV(Cs=Cs, cv = 5, scoring='neg_log_loss', penalty='l2', multi_class='ovr')\n",
    "lrcv_L2.fit(X_train, y_train)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrcv_L2.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dict with classes as the keys, and the values as the grid of scores obtained during cross-validating each fold,\n",
    "# Each dict value has shape (n_folds, len(Cs))\n",
    "n_Cs = len(Cs)\n",
    "n_classes = 9\n",
    "scores =  np.zeros((n_classes,n_Cs))\n",
    "\n",
    "for j in range(n_classes):\n",
    "        scores[j][:] = np.mean(lrcv_L2.scores_[j],axis = 0)\n",
    "    \n",
    "mse_mean = -np.mean(scores, axis = 0)\n",
    "pyplot.plot(np.log10(Cs), mse_mean.reshape(n_Cs,1)) \n",
    "#plt.plot(np.log10(reg.Cs)*np.ones(3), [0.28, 0.29, 0.30])\n",
    "pyplot.xlabel('log(C)')\n",
    "pyplot.ylabel('neg-logloss')\n",
    "pyplot.show()\n",
    "\n",
    "#print ('C is:',lr_cv.C_)  #对多类分类问题，每个类别的分类器有一个C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
