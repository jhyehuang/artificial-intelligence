{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic 回归——Otto商品分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们以Kaggle 2015年举办的Otto Group Product Classification Challenge竞赛数据为例，分别调用缺省参数LogisticRegression、LogisticRegression + GridSearchCV以及LogisticRegressionCV进行参数调优。实际应用中LogisticRegression + GridSearchCV或LogisticRegressionCV任选一个即可。\n",
    "\n",
    "Otto数据集是著名电商Otto提供的一个多类商品分类问题，类别数=9. 每个样本有93维数值型特征（整数，表示某种事件发生的次数，已经进行过脱敏处理）。 竞赛官网：https://www.kaggle.com/c/otto-group-product-classification-challenge/data\n",
    "\n",
    "\n",
    "第一名：https://www.kaggle.com/c/otto-group-product-classification-challenge/discussion/14335\n",
    "第二名：http://blog.kaggle.com/2015/06/09/otto-product-classification-winners-interview-2nd-place-alexander-guschin/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 首先 import 必要的模块\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#竞赛的评价指标为logloss\n",
    "from sklearn.metrics import log_loss  \n",
    "\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据 & 数据探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  feat_9  \\\n",
       "0   1       1       0       0       0       0       0       0       0       0   \n",
       "1   2       0       0       0       0       0       0       0       1       0   \n",
       "2   3       0       0       0       0       0       0       0       1       0   \n",
       "3   4       1       0       0       1       6       1       5       0       0   \n",
       "4   5       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "    ...     feat_85  feat_86  feat_87  feat_88  feat_89  feat_90  feat_91  \\\n",
       "0   ...           1        0        0        0        0        0        0   \n",
       "1   ...           0        0        0        0        0        0        0   \n",
       "2   ...           0        0        0        0        0        0        0   \n",
       "3   ...           0        1        2        0        0        0        0   \n",
       "4   ...           1        0        0        0        0        1        0   \n",
       "\n",
       "   feat_92  feat_93   target  \n",
       "0        0        0  Class_1  \n",
       "1        0        0  Class_1  \n",
       "2        0        0  Class_1  \n",
       "3        0        0  Class_1  \n",
       "4        0        0  Class_1  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取数据\n",
    "# path to where the data lies\n",
    "dpath = './data/'\n",
    "train = pd.read_csv(dpath +\"Otto_train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 61878 entries, 0 to 61877\n",
      "Data columns (total 95 columns):\n",
      "id         61878 non-null int64\n",
      "feat_1     61878 non-null int64\n",
      "feat_2     61878 non-null int64\n",
      "feat_3     61878 non-null int64\n",
      "feat_4     61878 non-null int64\n",
      "feat_5     61878 non-null int64\n",
      "feat_6     61878 non-null int64\n",
      "feat_7     61878 non-null int64\n",
      "feat_8     61878 non-null int64\n",
      "feat_9     61878 non-null int64\n",
      "feat_10    61878 non-null int64\n",
      "feat_11    61878 non-null int64\n",
      "feat_12    61878 non-null int64\n",
      "feat_13    61878 non-null int64\n",
      "feat_14    61878 non-null int64\n",
      "feat_15    61878 non-null int64\n",
      "feat_16    61878 non-null int64\n",
      "feat_17    61878 non-null int64\n",
      "feat_18    61878 non-null int64\n",
      "feat_19    61878 non-null int64\n",
      "feat_20    61878 non-null int64\n",
      "feat_21    61878 non-null int64\n",
      "feat_22    61878 non-null int64\n",
      "feat_23    61878 non-null int64\n",
      "feat_24    61878 non-null int64\n",
      "feat_25    61878 non-null int64\n",
      "feat_26    61878 non-null int64\n",
      "feat_27    61878 non-null int64\n",
      "feat_28    61878 non-null int64\n",
      "feat_29    61878 non-null int64\n",
      "feat_30    61878 non-null int64\n",
      "feat_31    61878 non-null int64\n",
      "feat_32    61878 non-null int64\n",
      "feat_33    61878 non-null int64\n",
      "feat_34    61878 non-null int64\n",
      "feat_35    61878 non-null int64\n",
      "feat_36    61878 non-null int64\n",
      "feat_37    61878 non-null int64\n",
      "feat_38    61878 non-null int64\n",
      "feat_39    61878 non-null int64\n",
      "feat_40    61878 non-null int64\n",
      "feat_41    61878 non-null int64\n",
      "feat_42    61878 non-null int64\n",
      "feat_43    61878 non-null int64\n",
      "feat_44    61878 non-null int64\n",
      "feat_45    61878 non-null int64\n",
      "feat_46    61878 non-null int64\n",
      "feat_47    61878 non-null int64\n",
      "feat_48    61878 non-null int64\n",
      "feat_49    61878 non-null int64\n",
      "feat_50    61878 non-null int64\n",
      "feat_51    61878 non-null int64\n",
      "feat_52    61878 non-null int64\n",
      "feat_53    61878 non-null int64\n",
      "feat_54    61878 non-null int64\n",
      "feat_55    61878 non-null int64\n",
      "feat_56    61878 non-null int64\n",
      "feat_57    61878 non-null int64\n",
      "feat_58    61878 non-null int64\n",
      "feat_59    61878 non-null int64\n",
      "feat_60    61878 non-null int64\n",
      "feat_61    61878 non-null int64\n",
      "feat_62    61878 non-null int64\n",
      "feat_63    61878 non-null int64\n",
      "feat_64    61878 non-null int64\n",
      "feat_65    61878 non-null int64\n",
      "feat_66    61878 non-null int64\n",
      "feat_67    61878 non-null int64\n",
      "feat_68    61878 non-null int64\n",
      "feat_69    61878 non-null int64\n",
      "feat_70    61878 non-null int64\n",
      "feat_71    61878 non-null int64\n",
      "feat_72    61878 non-null int64\n",
      "feat_73    61878 non-null int64\n",
      "feat_74    61878 non-null int64\n",
      "feat_75    61878 non-null int64\n",
      "feat_76    61878 non-null int64\n",
      "feat_77    61878 non-null int64\n",
      "feat_78    61878 non-null int64\n",
      "feat_79    61878 non-null int64\n",
      "feat_80    61878 non-null int64\n",
      "feat_81    61878 non-null int64\n",
      "feat_82    61878 non-null int64\n",
      "feat_83    61878 non-null int64\n",
      "feat_84    61878 non-null int64\n",
      "feat_85    61878 non-null int64\n",
      "feat_86    61878 non-null int64\n",
      "feat_87    61878 non-null int64\n",
      "feat_88    61878 non-null int64\n",
      "feat_89    61878 non-null int64\n",
      "feat_90    61878 non-null int64\n",
      "feat_91    61878 non-null int64\n",
      "feat_92    61878 non-null int64\n",
      "feat_93    61878 non-null int64\n",
      "target     61878 non-null object\n",
      "dtypes: int64(94), object(1)\n",
      "memory usage: 44.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_84</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.00000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30939.500000</td>\n",
       "      <td>0.38668</td>\n",
       "      <td>0.263066</td>\n",
       "      <td>0.901467</td>\n",
       "      <td>0.779081</td>\n",
       "      <td>0.071043</td>\n",
       "      <td>0.025696</td>\n",
       "      <td>0.193704</td>\n",
       "      <td>0.662433</td>\n",
       "      <td>1.011296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070752</td>\n",
       "      <td>0.532306</td>\n",
       "      <td>1.128576</td>\n",
       "      <td>0.393549</td>\n",
       "      <td>0.874915</td>\n",
       "      <td>0.457772</td>\n",
       "      <td>0.812421</td>\n",
       "      <td>0.264941</td>\n",
       "      <td>0.380119</td>\n",
       "      <td>0.126135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17862.784315</td>\n",
       "      <td>1.52533</td>\n",
       "      <td>1.252073</td>\n",
       "      <td>2.934818</td>\n",
       "      <td>2.788005</td>\n",
       "      <td>0.438902</td>\n",
       "      <td>0.215333</td>\n",
       "      <td>1.030102</td>\n",
       "      <td>2.255770</td>\n",
       "      <td>3.474822</td>\n",
       "      <td>...</td>\n",
       "      <td>1.151460</td>\n",
       "      <td>1.900438</td>\n",
       "      <td>2.681554</td>\n",
       "      <td>1.575455</td>\n",
       "      <td>2.115466</td>\n",
       "      <td>1.527385</td>\n",
       "      <td>4.597804</td>\n",
       "      <td>2.045646</td>\n",
       "      <td>0.982385</td>\n",
       "      <td>1.201720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15470.250000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30939.500000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>46408.750000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61.00000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>87.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id       feat_1        feat_2        feat_3        feat_4  \\\n",
       "count  61878.000000  61878.00000  61878.000000  61878.000000  61878.000000   \n",
       "mean   30939.500000      0.38668      0.263066      0.901467      0.779081   \n",
       "std    17862.784315      1.52533      1.252073      2.934818      2.788005   \n",
       "min        1.000000      0.00000      0.000000      0.000000      0.000000   \n",
       "25%    15470.250000      0.00000      0.000000      0.000000      0.000000   \n",
       "50%    30939.500000      0.00000      0.000000      0.000000      0.000000   \n",
       "75%    46408.750000      0.00000      0.000000      0.000000      0.000000   \n",
       "max    61878.000000     61.00000     51.000000     64.000000     70.000000   \n",
       "\n",
       "             feat_5        feat_6        feat_7        feat_8        feat_9  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.071043      0.025696      0.193704      0.662433      1.011296   \n",
       "std        0.438902      0.215333      1.030102      2.255770      3.474822   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      1.000000      0.000000   \n",
       "max       19.000000     10.000000     38.000000     76.000000     43.000000   \n",
       "\n",
       "           ...            feat_84       feat_85       feat_86       feat_87  \\\n",
       "count      ...       61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       ...           0.070752      0.532306      1.128576      0.393549   \n",
       "std        ...           1.151460      1.900438      2.681554      1.575455   \n",
       "min        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "25%        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "50%        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "75%        ...           0.000000      0.000000      1.000000      0.000000   \n",
       "max        ...          76.000000     55.000000     65.000000     67.000000   \n",
       "\n",
       "            feat_88       feat_89       feat_90       feat_91       feat_92  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.874915      0.457772      0.812421      0.264941      0.380119   \n",
       "std        2.115466      1.527385      4.597804      2.045646      0.982385   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       30.000000     61.000000    130.000000     52.000000     19.000000   \n",
       "\n",
       "            feat_93  \n",
       "count  61878.000000  \n",
       "mean       0.126135  \n",
       "std        1.201720  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max       87.000000  \n",
       "\n",
       "[8 rows x 94 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 各属性的统计特性\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAELCAYAAAARNxsIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f5b22df588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Target 分布，看看各类样本分布是否均衡\n",
    "sns.countplot(train.target);\n",
    "pyplot.xlabel('target');\n",
    "pyplot.ylabel('Number of occurrences');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各类样本不均衡。交叉验证对分类任务缺省的是采用StratifiedKFold，在每折采样时根据各类样本按比例采样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将类别字符串变成数字\n",
    "# drop ids and get labels\n",
    "y_train = train['target']   #形式为Class_x\n",
    "y_train = y_train.map(lambda s: s[6:])\n",
    "y_train = y_train.map(lambda s: int(s)-1)\n",
    "\n",
    "train = train.drop([\"id\", \"target\"], axis=1)\n",
    "X_train = np.array(train)\n",
    "\n",
    "#如果计算资源有限，也可只取少量样本，如取前1000个样本\n",
    "#（分类中其实还需要确保取出来的这部分样本各类样本的比例和总体一致）\n",
    "#n_trains = 1000\n",
    "#y_train = train.target.values[:n_trains]\n",
    "\n",
    "#或者考虑用train_test_split而不是交叉验证来验证模型性能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# 数据标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 初始化特征的标准化器\n",
    "ss_X = StandardScaler()\n",
    "\n",
    "# 分别对训练和测试数据的特征进行标准化处理\n",
    "X_train = ss_X.fit_transform(X_train)\n",
    "#X_test = ss_X.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### default Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr= LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# 交叉验证用于评估模型性能和进行参数调优（模型选择）\n",
    "#分类任务中交叉验证缺省是采用StratifiedKFold\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "loss = cross_val_score(lr, X_train, y_train, cv=5, scoring='neg_log_loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss of each fold is:  [0.67686644 0.68182093 0.66838122 0.66628669 0.6743933 ]\n",
      "cv logloss is: 0.6735497161501911\n"
     ]
    }
   ],
   "source": [
    "print ('logloss of each fold is: ',-loss)\n",
    "print ('cv logloss is:', -loss.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正则化的 Logistic Regression及参数调优"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logistic回归的需要调整超参数有：C（正则系数，一般在log域（取log后的值）均匀设置候选参数）和正则函数penalty（L2/L1） \n",
    "目标函数为：J = sum(logloss(f(xi), yi)) + C* penalty \n",
    "\n",
    "在sklearn框架下，不同学习器的参数调整步骤相同：\n",
    "设置候选参数集合\n",
    "调用GridSearchCV\n",
    "调用fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_log_loss', verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#需要调优的参数\n",
    "# 请尝试将L1正则和L2正则分开，并配合合适的优化求解算法（slover）\n",
    "#tuned_parameters = {'penalty':['l1','l2'],\n",
    "#                   'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "#                   }\n",
    "penaltys = ['l1','l2']\n",
    "Cs = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "tuned_parameters = dict(penalty = penaltys, C = Cs)\n",
    "\n",
    "lr_penalty= LogisticRegression()\n",
    "grid= GridSearchCV(lr_penalty, tuned_parameters,cv=5, scoring='neg_log_loss')\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 3.09015694,  8.57042618,  7.80362616, 14.87754464, 24.13433571,\n",
       "        25.70490332, 43.75074935, 35.259903  , 61.15138531, 38.08733344,\n",
       "        65.814924  , 44.3284411 , 72.96374745, 44.93813267]),\n",
       " 'mean_score_time': array([0.02145977, 0.01955166, 0.01969357, 0.0176774 , 0.01637301,\n",
       "        0.01787329, 0.02105594, 0.02470946, 0.01765656, 0.01884995,\n",
       "        0.0266561 , 0.02274213, 0.01928916, 0.01932082]),\n",
       " 'mean_test_score': array([-1.17705999, -1.02651724, -0.77504812, -0.76020957, -0.68195576,\n",
       "        -0.68690551, -0.67238129, -0.67354989, -0.67188588, -0.67184432,\n",
       "        -0.67190048, -0.67183317, -0.67190824, -0.67187322]),\n",
       " 'mean_train_score': array([-1.1759756 , -1.02389825, -0.77092999, -0.75433198, -0.67255334,\n",
       "        -0.67728069, -0.6604319 , -0.66191607, -0.65923081, -0.65940468,\n",
       "        -0.6591296 , -0.65909351, -0.65911874, -0.65906414]),\n",
       " 'param_C': masked_array(data=[0.001, 0.001, 0.01, 0.01, 0.1, 0.1, 1, 1, 10, 10, 100,\n",
       "                    100, 1000, 1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
       "                    'l2', 'l1', 'l2', 'l1', 'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.001, 'penalty': 'l1'},\n",
       "  {'C': 0.001, 'penalty': 'l2'},\n",
       "  {'C': 0.01, 'penalty': 'l1'},\n",
       "  {'C': 0.01, 'penalty': 'l2'},\n",
       "  {'C': 0.1, 'penalty': 'l1'},\n",
       "  {'C': 0.1, 'penalty': 'l2'},\n",
       "  {'C': 1, 'penalty': 'l1'},\n",
       "  {'C': 1, 'penalty': 'l2'},\n",
       "  {'C': 10, 'penalty': 'l1'},\n",
       "  {'C': 10, 'penalty': 'l2'},\n",
       "  {'C': 100, 'penalty': 'l1'},\n",
       "  {'C': 100, 'penalty': 'l2'},\n",
       "  {'C': 1000, 'penalty': 'l1'},\n",
       "  {'C': 1000, 'penalty': 'l2'}],\n",
       " 'rank_test_score': array([14, 13, 12, 11,  9, 10,  7,  8,  4,  2,  5,  1,  6,  3]),\n",
       " 'split0_test_score': array([-1.18017451, -1.02714364, -0.77838917, -0.76291001, -0.68501405,\n",
       "        -0.69036097, -0.6759086 , -0.67686644, -0.67556077, -0.67545194,\n",
       "        -0.67555023, -0.67548784, -0.67554839, -0.67551244]),\n",
       " 'split0_train_score': array([-1.17531323, -1.02375019, -0.77031552, -0.75376261, -0.67180375,\n",
       "        -0.67655336, -0.65974911, -0.66119247, -0.65854525, -0.65871674,\n",
       "        -0.65844733, -0.65841174, -0.65843717, -0.65838281]),\n",
       " 'split1_test_score': array([-1.18110203, -1.03204185, -0.78308101, -0.76713379, -0.68953139,\n",
       "        -0.6943296 , -0.68054593, -0.68182093, -0.68034261, -0.68026919,\n",
       "        -0.68042845, -0.68035094, -0.68043632, -0.68041516]),\n",
       " 'split1_train_score': array([-1.1733616 , -1.02168815, -0.76813054, -0.7515705 , -0.6695701 ,\n",
       "        -0.67431592, -0.65734027, -0.65879158, -0.65613123, -0.65629471,\n",
       "        -0.65603153, -0.6559914 , -0.65601589, -0.65596083]),\n",
       " 'split2_test_score': array([-1.17464783, -1.02087093, -0.76888805, -0.75377286, -0.67631842,\n",
       "        -0.68101949, -0.66728694, -0.66838122, -0.66687642, -0.66685597,\n",
       "        -0.66685764, -0.66680775, -0.6668506 , -0.66680983]),\n",
       " 'split2_train_score': array([-1.17709368, -1.02534114, -0.77254828, -0.75591744, -0.67375264,\n",
       "        -0.6785515 , -0.66150382, -0.66304618, -0.66030155, -0.66048001,\n",
       "        -0.66020758, -0.66016491, -0.66019298, -0.66013654]),\n",
       " 'split3_test_score': array([-1.17393696, -1.02329239, -0.76921628, -0.75495946, -0.67556669,\n",
       "        -0.68072181, -0.66529706, -0.66628669, -0.66463419, -0.66442351,\n",
       "        -0.66471164, -0.66459398, -0.66477241, -0.66473165]),\n",
       " 'split3_train_score': array([-1.17744768, -1.02519383, -0.77292398, -0.75607063, -0.67453391,\n",
       "        -0.67927736, -0.66250875, -0.66405052, -0.66130393, -0.66149458,\n",
       "        -0.66118639, -0.6611647 , -0.6611991 , -0.66113495]),\n",
       " 'split4_test_score': array([-1.17543713, -1.02923794, -0.77566513, -0.76227154, -0.68334773,\n",
       "        -0.68809502, -0.6728669 , -0.6743933 , -0.67201418, -0.67221987,\n",
       "        -0.67195317, -0.67192411, -0.67193224, -0.67189573]),\n",
       " 'split4_train_score': array([-1.17666183, -1.02351792, -0.77073164, -0.7543387 , -0.67310628,\n",
       "        -0.67770533, -0.66105755, -0.6624996 , -0.65987209, -0.66003737,\n",
       "        -0.65977519, -0.65973481, -0.65974857, -0.6597056 ]),\n",
       " 'std_fit_time': array([0.08475201, 0.38074819, 0.12241048, 0.43574093, 0.75074214,\n",
       "        0.4032308 , 1.5632345 , 1.54178148, 1.53884852, 1.08528703,\n",
       "        4.10820786, 0.94222154, 5.13069349, 1.46300453]),\n",
       " 'std_score_time': array([0.00215597, 0.00539147, 0.00213858, 0.00143915, 0.00617274,\n",
       "        0.00121702, 0.00179364, 0.00535924, 0.00206618, 0.00304082,\n",
       "        0.017971  , 0.00604267, 0.00253967, 0.00695025]),\n",
       " 'std_test_score': array([0.0029748 , 0.00401494, 0.00544131, 0.00506934, 0.00531584,\n",
       "        0.00531725, 0.00557656, 0.00564982, 0.00570495, 0.00572887,\n",
       "        0.00571267, 0.00571999, 0.00570075, 0.00570723]),\n",
       " 'std_train_score': array([0.00149397, 0.00132752, 0.00172329, 0.00164235, 0.00173945,\n",
       "        0.00173786, 0.00178203, 0.00181437, 0.0017851 , 0.00179274,\n",
       "        0.00178173, 0.00178532, 0.00178722, 0.00178575])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the complete results (list of named tuples)\n",
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6718331728028712\n",
      "{'C': 100, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "print(-grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果最佳值在候选参数的边缘，最好再尝试更大的候选参数或更小的候选参数，直到找到拐点。\n",
    "l2, c=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f5b2a5d7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#pd.DataFrame(grid.cv_results_).to_csv('LogisticGridSearchCV_Otto.csv')\n",
    "#cvresult = pd.DataFrame.from_csv('LogisticGridSearchCV_Otto.csv')\n",
    "#test_means = cv_results['mean_test_score']\n",
    "#test_stds = cv_results['std_test_score'] \n",
    "#train_means = cvresult['mean_train_score']\n",
    "#train_stds = cvresult['std_train_score'] \n",
    "\n",
    "\n",
    "# plot CV误差曲线\n",
    "test_means = grid.cv_results_[ 'mean_test_score' ]\n",
    "test_stds = grid.cv_results_[ 'std_test_score' ]\n",
    "train_means = grid.cv_results_[ 'mean_train_score' ]\n",
    "train_stds = grid.cv_results_[ 'std_train_score' ]\n",
    "\n",
    "\n",
    "# plot results\n",
    "n_Cs = len(Cs)\n",
    "number_penaltys = len(penaltys)\n",
    "test_scores = np.array(test_means).reshape(n_Cs,number_penaltys)\n",
    "train_scores = np.array(train_means).reshape(n_Cs,number_penaltys)\n",
    "test_stds = np.array(test_stds).reshape(n_Cs,number_penaltys)\n",
    "train_stds = np.array(train_stds).reshape(n_Cs,number_penaltys)\n",
    "\n",
    "x_axis = np.log10(Cs)\n",
    "for i, value in enumerate(penaltys):\n",
    "    #pyplot.plot(log(Cs), test_scores[i], label= 'penalty:'   + str(value))\n",
    "    pyplot.errorbar(x_axis, test_scores[:,i], yerr=test_stds[:,i] ,label = penaltys[i] +' Test')\n",
    "    pyplot.errorbar(x_axis, train_scores[:,i], yerr=train_stds[:,i] ,label = penaltys[i] +' Train')\n",
    "    \n",
    "pyplot.legend()\n",
    "pyplot.xlabel( 'log(C)' )                                                                                                      \n",
    "pyplot.ylabel( 'neg-logloss' )\n",
    "pyplot.savefig('LogisticGridSearchCV_C.png' )\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上图给出了L1正则和L2正则下、不同正则参数C对应的模型在训练集上测试集上的正确率（score）。可以看出在训练集上C越大（正则越少）的模型性能越好；但在测试集上当C=100时性能最好（L1正则和L2正则均是）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用LogisticRegressionCV实现正则化的 Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1正则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=[1, 10, 100, 1000], class_weight=None, cv=5,\n",
       "           dual=False, fit_intercept=True, intercept_scaling=1.0,\n",
       "           max_iter=100, multi_class='ovr', n_jobs=1, penalty='l1',\n",
       "           random_state=None, refit=True, scoring='neg_log_loss',\n",
       "           solver='liblinear', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "Cs = [1, 10,100,1000]\n",
    "\n",
    "# 大量样本（6W+）、高维度（93），L1正则 --> 可选用saga优化求解器(0.19版本新功能)\n",
    "# LogisticRegressionCV比GridSearchCV快\n",
    "lrcv_L1 = LogisticRegressionCV(Cs=Cs, cv = 5, scoring='neg_log_loss', penalty='l1', solver='liblinear', multi_class='ovr')\n",
    "lrcv_L1.fit(X_train, y_train)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([[-0.08352365, -0.08351856, -0.08351933, -0.08351929],\n",
       "        [-0.08855308, -0.08870833, -0.08872636, -0.08872905],\n",
       "        [-0.08310827, -0.08322738, -0.08324102, -0.08324252],\n",
       "        [-0.08218088, -0.08218961, -0.08219014, -0.0821903 ],\n",
       "        [-0.08079021, -0.08076725, -0.08076565, -0.08076543]]),\n",
       " 1: array([[-0.31682808, -0.3168224 , -0.31682248, -0.31682286],\n",
       "        [-0.32033005, -0.32039094, -0.32039779, -0.32039685],\n",
       "        [-0.31523828, -0.315266  , -0.31526994, -0.3152704 ],\n",
       "        [-0.31668867, -0.316692  , -0.31669249, -0.31669321],\n",
       "        [-0.31923682, -0.3192861 , -0.319292  , -0.31929392]]),\n",
       " 2: array([[-0.2614059 , -0.26141909, -0.26142113, -0.2614209 ],\n",
       "        [-0.26185397, -0.26188024, -0.2618836 , -0.26188394],\n",
       "        [-0.26767719, -0.26772427, -0.26772966, -0.26772977],\n",
       "        [-0.26380702, -0.26382853, -0.26383127, -0.26383135],\n",
       "        [-0.26326469, -0.26328787, -0.26329084, -0.26329108]]),\n",
       " 3: array([[-0.13062817, -0.13080862, -0.13082931, -0.13083133],\n",
       "        [-0.12742609, -0.12747523, -0.12748409, -0.12748491],\n",
       "        [-0.12529079, -0.1252929 , -0.12529455, -0.12529475],\n",
       "        [-0.12718125, -0.12721705, -0.12722162, -0.12722212],\n",
       "        [-0.13061293, -0.13074825, -0.1307664 , -0.13076777]]),\n",
       " 4: array([[-0.01544921, -0.01577718, -0.01586202, -0.01587227],\n",
       "        [-0.01202254, -0.01223055, -0.01236561, -0.01238573],\n",
       "        [-0.01433829, -0.01462019, -0.01466665, -0.01467074],\n",
       "        [-0.01854224, -0.01919431, -0.01948951, -0.01953675],\n",
       "        [-0.01407928, -0.01390084, -0.01391844, -0.01392135]]),\n",
       " 5: array([[-0.11884125, -0.11891576, -0.11892476, -0.11892357],\n",
       "        [-0.11644073, -0.11660582, -0.11662481, -0.11662482],\n",
       "        [-0.10609706, -0.10607412, -0.1060717 , -0.1060704 ],\n",
       "        [-0.10410847, -0.10414566, -0.10414997, -0.10415081],\n",
       "        [-0.10736397, -0.10739656, -0.10740106, -0.10740051]]),\n",
       " 6: array([[-0.10058115, -0.10063923, -0.1006459 , -0.10064652],\n",
       "        [-0.11305491, -0.11313317, -0.11314174, -0.11314248],\n",
       "        [-0.1045056 , -0.10452738, -0.10453013, -0.10453036],\n",
       "        [-0.10078717, -0.10081451, -0.100818  , -0.10081836],\n",
       "        [-0.10068647, -0.10074327, -0.1007502 , -0.10075105]]),\n",
       " 7: array([[-0.10177204, -0.10178549, -0.10178888, -0.10178835],\n",
       "        [-0.11022212, -0.11031318, -0.110324  , -0.1103246 ],\n",
       "        [-0.10008581, -0.1000788 , -0.10007813, -0.10007875],\n",
       "        [-0.10345974, -0.1034797 , -0.10348231, -0.10348132],\n",
       "        [-0.10526862, -0.10530915, -0.10531372, -0.10531497]]),\n",
       " 8: array([[-0.09436455, -0.09453016, -0.09454901, -0.09455115],\n",
       "        [-0.08332564, -0.08332997, -0.08333143, -0.08333152],\n",
       "        [-0.09287017, -0.09289534, -0.09289867, -0.09289921],\n",
       "        [-0.09000713, -0.09010199, -0.09011296, -0.09011402],\n",
       "        [-0.09095369, -0.09095007, -0.09095106, -0.09095098]])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrcv_L1.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ4AAAERCAYAAABLmsECAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f5b22a1048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# scores_：dict with classes as the keys, and the values as the grid of scores obtained during cross-validating each fold,\n",
    "# Each dict value has shape (n_folds, len(Cs))\n",
    "n_Cs = len(Cs)\n",
    "n_classes = 9\n",
    "scores =  np.zeros((n_classes,n_Cs))\n",
    "\n",
    "for j in range(n_classes):\n",
    "        scores[j][:] = np.mean(lrcv_L1.scores_[j],axis = 0)\n",
    "    \n",
    "mse_mean = -np.mean(scores, axis = 0)\n",
    "pyplot.plot(np.log10(Cs), mse_mean.reshape(n_Cs,1)) \n",
    "#plt.plot(np.log10(reg.Cs)*np.ones(3), [0.28, 0.29, 0.30])\n",
    "pyplot.xlabel('log(C)')\n",
    "pyplot.ylabel('neg-logloss')\n",
    "pyplot.show()\n",
    "\n",
    "#print ('C is:',lr_cv.C_)  #对多类分类问题，每个类别的分类器有一个C\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个score似乎和GridSearchCV得到的Score不一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.47983513e-02, -1.82111796e-01, -3.33933490e-01,\n",
       "        -1.32159692e-01,  6.85647921e-02,  5.58920147e-02,\n",
       "         8.73009244e-02,  6.00890202e-02, -1.02846444e+00,\n",
       "         2.67962145e-02, -1.40904919e+00,  1.41483779e-02,\n",
       "        -2.80662896e-01, -1.10583259e+00, -1.67712351e+00,\n",
       "        -7.18307309e-02,  3.14197743e-01,  1.31892921e-01,\n",
       "        -6.49728162e-01,  1.16814486e-01, -5.46112046e-03,\n",
       "         5.97534942e-02,  1.18200595e-01,  3.36824922e-01,\n",
       "        -7.92709318e-01, -1.30464974e-01, -1.27915229e-01,\n",
       "         7.43359802e-02, -2.85529386e-01,  2.22178705e-01,\n",
       "        -4.11333154e-01,  8.97200746e-02, -2.90528847e-01,\n",
       "        -1.04228266e+00, -5.83943338e-01, -1.71004212e-01,\n",
       "         2.03486170e-01, -1.02887702e-01, -1.44845167e-01,\n",
       "        -1.26939442e+00, -2.59965566e-01, -4.48989137e-01,\n",
       "        -1.75090180e+00,  1.44900218e-01, -3.11405618e-01,\n",
       "        -2.38874209e-01, -2.03724961e-01,  3.65433667e-02,\n",
       "         4.31045992e-02, -5.61952659e-01,  2.54899777e-02,\n",
       "         6.55763611e-03,  1.63086010e-01, -1.62098470e-02,\n",
       "         1.24765028e-01, -2.06484211e-01, -1.81555251e-01,\n",
       "        -2.20088882e+00, -2.52153127e-01, -5.19300448e-01,\n",
       "         1.77443641e-01,  9.68531319e-02, -4.83255136e-02,\n",
       "        -2.12130567e-01, -6.88273213e-03,  2.26486248e-01,\n",
       "         3.03912319e-01, -3.52354612e-01, -9.48697725e-01,\n",
       "         3.04785315e-01,  8.45208222e-02, -4.48325931e-01,\n",
       "        -2.29806614e-01, -6.47964034e-01, -5.76862555e-01,\n",
       "         2.60705611e-01,  2.36401180e-01, -5.27789576e-02,\n",
       "         1.06502361e-01,  6.54578356e-02,  1.66413564e-01,\n",
       "        -2.29215327e-01,  4.07706526e-03,  1.01305921e-01,\n",
       "         6.92858869e-02, -3.76284795e-01, -5.63788043e-02,\n",
       "        -1.40281745e-01, -1.01787388e-01, -1.00722281e+00,\n",
       "        -1.47019594e-01,  8.10136279e-02, -2.31347334e-01],\n",
       "       [-2.35716028e-03, -2.58710662e-01, -2.73815271e-01,\n",
       "         1.76653929e-02,  5.09133662e-02,  1.96452254e-02,\n",
       "        -1.33465670e-01, -2.13470857e-01,  9.72174620e-02,\n",
       "         2.75772356e-02, -9.73130784e-01,  1.12272034e-01,\n",
       "        -4.38453858e-01,  1.11918301e-01,  1.24076896e-01,\n",
       "         1.09517392e-01, -5.77363261e-01,  2.57977250e-02,\n",
       "        -7.27745521e-01, -1.80210794e-01,  3.86811508e-02,\n",
       "        -4.17163358e-02, -2.52922984e-01,  1.81055233e-01,\n",
       "         2.09129084e-01, -1.18373785e+00, -5.97473015e-01,\n",
       "        -9.34686943e-02, -7.77181811e-01, -7.00249212e-01,\n",
       "        -2.20636518e-02, -2.03023203e-01,  2.47105693e-01,\n",
       "        -6.28020213e-01, -2.12025040e-01, -8.42019632e-01,\n",
       "        -2.80547370e-02,  6.64513865e-02, -4.04612410e-01,\n",
       "         1.16181597e-01, -4.43033272e-01, -7.57336824e-01,\n",
       "        -1.12638048e-02, -1.76568622e-02, -1.57435595e-02,\n",
       "        -3.01228122e-01, -4.16852323e-01,  3.75841048e-01,\n",
       "         1.85838427e-02, -1.57316139e-01, -2.06685100e-01,\n",
       "         2.32377516e-02, -3.92742202e-01,  1.73131733e-01,\n",
       "        -8.12063139e-02, -2.29058590e-01, -5.37900843e-01,\n",
       "        -5.05671544e-01, -7.13395042e-01, -8.52159812e-01,\n",
       "        -2.21931370e-01, -4.98471015e-02,  1.16936236e-01,\n",
       "         1.53711920e-01,  3.82717778e-02,  8.63381193e-02,\n",
       "         1.29081628e-01, -8.49584851e-01, -4.37885608e-01,\n",
       "        -1.64752961e-02, -3.91304256e-01,  1.63166648e-01,\n",
       "        -2.59828496e-01,  6.73141535e-02, -1.06378055e+00,\n",
       "        -2.39374977e-01,  2.91589946e-01, -1.00059080e+00,\n",
       "        -2.60479624e-01, -2.53799712e-01, -8.89894432e-02,\n",
       "         2.37640108e-02, -7.53296041e-02, -8.36892029e-01,\n",
       "        -1.93399076e-02,  1.17399893e-02,  6.72422482e-02,\n",
       "        -7.36412116e-02,  3.23250098e-02, -1.07159019e+00,\n",
       "        -7.39547748e-01,  7.96704354e-02, -6.05786816e-02],\n",
       "       [-1.20258906e-01, -7.64021074e-02, -2.21209937e-01,\n",
       "        -1.06297942e-01, -9.29132633e-02, -1.35724956e-02,\n",
       "        -1.93428117e-01, -1.43681416e-01,  1.99598084e-01,\n",
       "        -5.43683359e-02, -7.40748601e-01, -2.93514447e-02,\n",
       "         2.75181401e-03,  1.42852638e-01,  7.85855548e-02,\n",
       "         1.56237133e-01, -4.65609588e-01, -6.89368153e-02,\n",
       "        -1.91745647e-01, -1.92109127e-01,  5.07695902e-02,\n",
       "        -7.94186384e-02,  1.12872922e-02,  1.76689908e-01,\n",
       "        -2.29533679e-02, -8.77114979e-01,  8.22922665e-02,\n",
       "        -8.53242353e-02,  8.74034196e-02,  2.21640614e-01,\n",
       "         5.55411339e-02,  2.51797371e-01, -6.48234406e-02,\n",
       "        -4.23982604e-01, -2.06989475e-01, -1.20209408e-01,\n",
       "        -2.16910923e-02,  9.41702214e-02, -2.15863618e-01,\n",
       "         2.20003474e-01,  1.54984904e-02, -4.50685104e-01,\n",
       "         3.32281889e-01, -4.10514478e-03, -2.68238729e-01,\n",
       "         1.71327640e-02, -6.01142578e-01, -7.55139113e-02,\n",
       "         2.47180965e-02,  9.79059646e-03, -1.24235013e-01,\n",
       "         1.05514840e-02, -1.08215422e-01, -2.39231489e-02,\n",
       "        -1.20837804e-02,  5.64841680e-02, -4.47530957e-01,\n",
       "        -3.09338365e-01, -4.11849848e-01, -2.69167734e+00,\n",
       "        -2.20528286e-01,  5.36747091e-02,  2.29722939e-02,\n",
       "         2.09141293e-01, -4.77769537e-02, -1.50007723e-02,\n",
       "        -4.27384523e-01, -1.80364548e-01, -1.08168815e+00,\n",
       "         6.17993345e-02,  1.36666812e-01, -2.89417139e-02,\n",
       "        -1.00915582e+00, -5.29086359e-01, -6.93592352e-01,\n",
       "        -4.45884906e-01, -4.46041149e-01, -1.07498087e-01,\n",
       "        -6.12582141e-02,  1.09299721e-01, -4.05320354e-02,\n",
       "        -3.36394242e-01,  2.99080651e-01, -7.41785652e-01,\n",
       "         1.25837622e-01,  1.78400766e-01, -1.12878479e-01,\n",
       "         9.70695527e-02,  1.94196320e-01, -7.12573676e-01,\n",
       "        -4.62815014e-01, -7.00849730e-01, -2.93366370e-01],\n",
       "       [ 2.46467127e-01, -3.22988462e-01, -6.37146190e-01,\n",
       "        -6.62580785e-01,  5.62328750e-02,  3.96488448e-03,\n",
       "        -1.61149777e-01, -2.46410517e-02, -6.19706378e-01,\n",
       "         6.15679231e-02, -1.24201218e+00, -1.16565600e-01,\n",
       "         7.45710198e-02,  2.83314847e-02,  3.71259978e-01,\n",
       "        -2.43889458e-02, -4.90876123e-01, -3.15996380e-01,\n",
       "        -1.02782374e-02,  8.78523804e-02, -7.92783142e-02,\n",
       "         6.31202143e-02,  4.69592303e-02, -8.20503409e-01,\n",
       "         3.39816036e-01,  6.93746308e-01,  4.05115219e-02,\n",
       "        -2.71919292e-01, -2.35556754e-01, -4.09211880e-01,\n",
       "        -1.04563625e-01, -2.21077370e-01, -2.50193572e-02,\n",
       "        -4.65574279e-01, -8.60274845e-01, -6.35554783e-03,\n",
       "        -1.26701253e-02, -6.33583683e-02, -6.31282021e-01,\n",
       "         5.57033240e-02, -2.13078695e-02,  1.40250326e-01,\n",
       "         6.75106080e-02,  1.13420273e-01, -7.47695732e-02,\n",
       "         0.00000000e+00, -9.64219542e-01, -4.40776236e-01,\n",
       "        -3.41900973e-01, -7.14741918e-02, -3.18398542e-01,\n",
       "         2.42274252e-01, -3.02292920e-02, -1.76729990e-01,\n",
       "         2.62498172e-02,  4.71013273e-02, -6.17871124e-01,\n",
       "        -2.05716569e+00, -6.83401742e-01, -1.36747882e-01,\n",
       "        -5.21471330e-01, -7.80218851e-01,  6.75842713e-02,\n",
       "         2.68866560e-03, -1.24228096e-01, -1.53704781e-02,\n",
       "        -8.73392401e-01, -6.52237033e-02, -4.43935731e-02,\n",
       "         1.45093636e-02, -2.21062628e-01, -1.45425788e-02,\n",
       "        -1.13285731e-01,  3.62172973e-02, -2.64805765e-01,\n",
       "        -9.86786783e-01, -4.34211894e-01, -6.38331126e-02,\n",
       "         8.54520146e-02,  8.39314860e-03, -1.46226056e-01,\n",
       "        -2.92988709e-01, -1.27264203e-01, -7.66740634e-01,\n",
       "         1.40825648e-01,  1.88056296e-01,  3.30549945e-01,\n",
       "         1.20555092e-01, -1.63756182e-01, -8.53227088e-01,\n",
       "         0.00000000e+00,  1.50240505e-01, -4.89964861e-01],\n",
       "       [-3.29971078e-01,  0.00000000e+00,  8.97222502e-01,\n",
       "        -1.85835416e-01, -5.92031029e-02, -6.89796516e-02,\n",
       "        -6.40954553e-01,  1.88770587e-01, -1.68918278e-02,\n",
       "        -4.94391480e-01, -3.41160098e+00,  2.09974922e-01,\n",
       "         9.22360422e-02, -1.30291649e+00, -8.36247632e-01,\n",
       "         2.37210537e-03, -1.52334227e+00,  1.87723931e-01,\n",
       "        -3.03272899e-01, -2.87993816e-02, -4.82840745e-01,\n",
       "         2.80671451e-01,  0.00000000e+00, -4.27065208e-01,\n",
       "        -1.19150550e+00, -1.66477552e+00, -4.60955537e-01,\n",
       "        -1.56246665e-01, -8.32467322e-01, -8.67235527e-01,\n",
       "         1.91190070e-01,  3.03125526e-01,  2.53297027e-01,\n",
       "         3.13804721e+00, -2.35388428e-01, -1.10611263e+00,\n",
       "         2.26395892e-02, -6.65716729e-02, -8.60157755e+00,\n",
       "        -4.67749272e-02, -1.25646598e-01, -4.60930987e-01,\n",
       "        -6.00501100e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -4.51917781e-01, -1.39185983e+00, -9.87617675e-02,\n",
       "         0.00000000e+00, -6.61505283e-01, -1.62970506e-01,\n",
       "        -1.12231366e+00, -4.15892928e-02, -6.06251950e-01,\n",
       "        -2.41675982e-01, -4.32948126e-01,  0.00000000e+00,\n",
       "        -8.34863746e-01, -3.47335553e+00, -2.57662877e+00,\n",
       "         0.00000000e+00, -4.42089944e-01, -9.05342144e-02,\n",
       "        -3.43708487e-01, -1.03188212e-01,  9.39724041e-02,\n",
       "        -4.26555996e-01, -5.67697225e-01, -7.43656895e-01,\n",
       "        -1.53553214e-01,  3.68921004e-01, -1.24332395e+00,\n",
       "        -5.05191493e+00,  0.00000000e+00, -3.09618511e+00,\n",
       "        -1.44436515e+00, -5.50832696e-01, -5.95731824e-01,\n",
       "         0.00000000e+00,  0.00000000e+00, -3.02704336e-01,\n",
       "        -2.72838472e-01, -4.05116594e+00, -1.39141854e+00,\n",
       "        -2.77600683e-01, -2.22971384e+00,  1.74006391e-01,\n",
       "        -7.56911687e-01, -3.95298793e-01, -8.03901619e-01,\n",
       "        -6.95622616e-01,  7.11032741e-02,  0.00000000e+00],\n",
       "       [ 9.61186350e-02,  8.14862785e-03,  2.60019517e-01,\n",
       "        -4.91536590e-03, -1.21934935e-01,  1.97571816e-02,\n",
       "        -1.76542072e-01, -1.52927665e-01, -5.80971410e-01,\n",
       "        -6.30001094e-02,  2.26958209e+00, -4.12261920e-02,\n",
       "         2.25291751e-03, -1.01875419e+00, -1.05401705e+00,\n",
       "         1.09217171e-03,  2.03321510e-02,  1.64894259e-01,\n",
       "        -6.12364863e-01, -2.80114890e-02,  6.97254229e-04,\n",
       "         6.85536897e-02,  5.62981412e-02, -1.81133774e-03,\n",
       "        -4.00491183e-01,  5.66346526e-01,  1.88054474e-01,\n",
       "        -2.46379132e-03,  1.32830869e-01, -2.88340784e-01,\n",
       "         8.00330289e-02, -1.83843932e-01, -1.44622526e-01,\n",
       "        -9.44719947e-01, -8.09221180e-01, -1.96726507e-01,\n",
       "        -8.96712289e-02, -1.58255666e-01,  4.00558748e-02,\n",
       "        -9.76954489e-01, -9.73534972e-02,  9.95066608e-01,\n",
       "        -1.97539732e-01,  1.41991160e-01,  7.69739955e-02,\n",
       "         2.30886943e-01,  7.10356967e-02, -2.38571348e-01,\n",
       "         4.98830471e-03,  3.55900802e-02,  1.35367598e-02,\n",
       "        -1.60937742e-01, -7.08367309e-02,  1.43750870e-01,\n",
       "         5.18319083e-02, -2.32070160e-01,  6.02311598e-01,\n",
       "        -4.83468980e-01,  6.15824865e-02,  1.22077675e+00,\n",
       "         3.32707534e-01, -5.15757400e-01, -1.22997386e-02,\n",
       "         2.95242718e-01, -4.20416418e-02,  2.45250983e-02,\n",
       "        -5.89722342e-03, -2.49083314e-01, -4.20835003e-01,\n",
       "        -5.21364428e-02, -1.49222169e-01, -6.20818504e-01,\n",
       "        -3.21017371e-01,  2.66793245e-01, -2.51648473e-01,\n",
       "        -2.46462840e-01, -1.29596632e-01, -9.09975645e-01,\n",
       "         1.24726124e-01, -6.91311996e-03,  2.89654367e-03,\n",
       "         8.84481801e-02, -4.15322884e-02, -2.54461550e-01,\n",
       "        -8.47591735e-02, -1.05797568e-01,  1.65129119e-01,\n",
       "        -4.06622914e-01, -2.21206499e-01, -6.92651119e-01,\n",
       "        -1.52257139e-02,  7.57855790e-02,  4.49188263e-01],\n",
       "       [-2.78582236e-02,  1.38454431e-01, -1.21616077e-01,\n",
       "        -1.06665039e-01, -1.08351442e-01,  8.04530966e-03,\n",
       "        -1.53559744e-02, -3.02719787e-01, -1.07137195e+00,\n",
       "         5.46625597e-02, -5.64121009e-01,  7.69630004e-02,\n",
       "        -3.82559603e-01, -4.75348797e-01, -1.32767156e+00,\n",
       "         2.62451384e-01,  1.46002811e-01, -4.57968100e-02,\n",
       "        -4.38157154e-01, -2.84392733e-02,  1.41167824e-02,\n",
       "        -6.12472280e-02,  2.55848948e-01,  7.70536250e-02,\n",
       "        -4.10413140e-01, -3.37871915e-01, -9.23255949e-01,\n",
       "         4.20299531e-03, -5.71009951e-02, -2.23626125e-01,\n",
       "        -6.64854143e-02,  6.61817994e-01, -8.00661802e-02,\n",
       "        -8.20051907e-01, -2.10311706e-01, -5.45604226e-01,\n",
       "         7.67848555e-02,  2.12952843e-01,  6.60985334e-01,\n",
       "        -8.60526824e-01, -1.71459177e-01, -2.46900847e-01,\n",
       "         2.02966105e-02,  5.44237433e-02,  1.97002811e-01,\n",
       "        -2.66971833e-01,  4.53012534e-02,  9.58285823e-02,\n",
       "         1.10513633e-01,  5.32208653e-01,  3.44514466e-02,\n",
       "         9.39552993e-02, -2.09587048e-01, -1.72733991e-01,\n",
       "         3.73460380e-02,  2.72144815e-01, -2.56984178e-03,\n",
       "        -4.43345861e-01, -1.04004549e-01, -3.65758964e-01,\n",
       "        -3.98388179e-01, -5.53002384e-01,  2.72293285e-03,\n",
       "         1.18648534e-01, -1.87687583e-02,  1.37062229e-01,\n",
       "        -2.16434071e-01, -3.11092868e-01, -5.28298654e-01,\n",
       "         1.27659171e-01,  2.58033086e-02, -2.87020436e-01,\n",
       "        -5.51632529e-01, -1.75737709e-01, -7.12738342e-01,\n",
       "        -1.83471065e-01, -3.00355387e-02, -1.61424952e-01,\n",
       "         6.64713029e-02, -2.76029285e-03,  9.90962127e-02,\n",
       "         9.90188682e-03,  1.19377383e-01, -9.00998417e-01,\n",
       "        -9.16294476e-02,  2.18411944e-01,  2.17895087e-03,\n",
       "        -8.24911103e-02, -2.63089956e-02, -4.77418969e-01,\n",
       "        -2.65363540e-02, -2.23377664e-01, -1.30639913e-01],\n",
       "       [ 9.06284746e-02, -2.26575458e-01, -3.49207315e-01,\n",
       "         9.43724153e-02, -1.31101409e-02,  5.75070802e-03,\n",
       "         1.14600825e-01, -1.40516947e-01, -1.80634126e-01,\n",
       "         1.06678746e-01, -1.59539658e+00,  3.80166046e-02,\n",
       "         1.64300583e-01, -1.02970337e+00, -1.66798799e+00,\n",
       "        -8.53050668e-02, -2.17064567e-01,  0.00000000e+00,\n",
       "         8.32712714e-01,  2.89492748e-01,  8.99245659e-03,\n",
       "         4.76177185e-02, -6.20839741e-02,  4.76139437e-02,\n",
       "        -1.98202607e-01, -4.27276781e-01, -9.37052975e-02,\n",
       "         2.03662696e-01, -7.29514083e-02, -1.84411058e-01,\n",
       "         1.65004528e-01, -2.55940407e-01,  3.87290054e-02,\n",
       "        -9.86966724e-01,  8.87810767e-01, -4.98272168e-01,\n",
       "         2.78245988e-01,  3.48949468e-01, -8.05745456e-01,\n",
       "        -9.30871856e-01,  4.54365475e-02, -4.94364389e-01,\n",
       "        -9.93559712e-01,  7.17350487e-03, -5.85729058e-01,\n",
       "         1.19799570e-01,  2.96698298e-01, -4.30254902e-01,\n",
       "        -8.90916895e-02, -2.37022235e-01,  6.06398913e-02,\n",
       "         5.61279625e-02, -4.06351559e-01,  1.21174413e-01,\n",
       "        -5.18338594e-02, -1.96614509e-01, -2.04254445e-01,\n",
       "         7.98548709e-01, -5.40425823e-01, -9.56205379e-01,\n",
       "        -1.18542305e-01, -6.90464578e-02, -4.40571728e-02,\n",
       "         4.79208199e-02,  8.86288987e-02,  5.84288984e-02,\n",
       "         9.17212618e-02,  7.44595243e-01,  1.44361685e+00,\n",
       "         3.82296650e-02,  3.22504886e-01, -5.26095314e-01,\n",
       "         6.85483176e-01,  3.13829165e-02,  1.10397951e+00,\n",
       "         9.07175633e-02, -3.48638526e-01,  4.44226910e-01,\n",
       "        -2.52332975e-01,  1.08093769e-01,  6.84379406e-02,\n",
       "        -1.23304118e-01,  9.92047854e-02,  1.68609627e-01,\n",
       "        -2.91896644e-01, -1.11614093e+00, -2.67695617e-01,\n",
       "        -3.89527331e-01,  1.45783981e-01,  1.53033621e+00,\n",
       "        -7.59527863e-01, -7.82488919e-02, -7.26897689e-02],\n",
       "       [ 1.35834188e-01, -7.72624817e-02, -1.26359886e-01,\n",
       "        -1.79367433e-01, -5.56997700e-02, -1.49620615e-01,\n",
       "        -1.15422958e-01,  1.63718049e-01, -8.56923989e-01,\n",
       "        -1.51816206e-01, -1.38844445e+00, -1.01060295e-01,\n",
       "         1.56021401e-01, -9.25136902e-01, -1.31535672e+00,\n",
       "         7.10386213e-02,  9.10596809e-02,  8.29877788e-02,\n",
       "        -4.85422510e-01, -1.81117261e-01,  1.33472506e-01,\n",
       "         3.29757566e-01, -2.29228907e-01, -2.26937783e-01,\n",
       "        -1.26075319e-01, -1.17450123e-01, -2.66581473e-02,\n",
       "        -3.53690908e-02, -2.09170530e-02,  6.06867597e-01,\n",
       "         1.98978280e-02,  3.45904790e-04,  1.73223984e-03,\n",
       "        -1.08148896e+00, -3.14501725e-01,  6.81194034e-01,\n",
       "        -2.06950549e-01, -3.11839474e-01, -5.87409778e-01,\n",
       "        -1.31881123e+00,  3.92806996e-01, -4.52312968e-01,\n",
       "        -1.08873806e+00,  0.00000000e+00, -1.48326096e+00,\n",
       "        -6.13080694e-01, -5.78668168e-01,  4.41009667e-02,\n",
       "        -8.62068782e-02, -2.08559526e-01,  3.45177038e-02,\n",
       "         5.65856550e-02,  2.71469091e-01, -1.13742331e-01,\n",
       "        -1.03655326e-01, -3.90889270e-02, -1.89923900e-01,\n",
       "        -3.98210597e-01,  7.43343009e-01, -8.66588655e-01,\n",
       "        -1.74955932e-01,  8.46608754e-01, -4.05068194e-02,\n",
       "        -7.02673975e-01, -8.49748561e-02,  1.22007321e-01,\n",
       "         2.28308303e-01, -1.95724582e-01, -7.90591963e-01,\n",
       "        -2.43180901e-01, -1.54345993e-01, -4.92264440e-01,\n",
       "        -7.82384273e-01,  1.00410046e-01, -2.80542043e-01,\n",
       "        -1.55293281e-01,  2.08757972e-01, -4.31026523e-01,\n",
       "         4.89770894e-02, -7.52779931e-02, -1.03560352e-01,\n",
       "         1.81653315e-01,  1.50248303e-01, -1.28442828e+00,\n",
       "        -1.89753316e-01, -2.79696843e-01,  1.18721207e-01,\n",
       "        -8.65098789e-01,  1.31042740e-01, -6.00624219e-01,\n",
       "         4.49183719e-01,  2.08298195e-01, -2.84045545e-01]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrcv_L1.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "惩罚不够，没有稀疏系数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2正则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=[1, 10, 100, 1000], class_weight=None, cv=5,\n",
       "           dual=False, fit_intercept=True, intercept_scaling=1.0,\n",
       "           max_iter=100, multi_class='ovr', n_jobs=1, penalty='l2',\n",
       "           random_state=None, refit=True, scoring='neg_log_loss',\n",
       "           solver='liblinear', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "Cs = [1, 10,100,1000]\n",
    "\n",
    "# 大量样本（6W+）、高维度（93），L2正则 --> 缺省用lbfgs，为了和GridSeachCV比较，也用liblinear\n",
    "\n",
    "lr_cv_L2 = LogisticRegressionCV(Cs=Cs, cv = 5, scoring='neg_log_loss', penalty='l2', solver='liblinear', multi_class='ovr')\n",
    "lr_cv_L2.fit(X_train, y_train)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lr_cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-aaa2af6807be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlr_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscores_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'lr_cv' is not defined"
     ]
    }
   ],
   "source": [
    "lr_cv.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dict with classes as the keys, and the values as the grid of scores obtained during cross-validating each fold,\n",
    "# Each dict value has shape (n_folds, len(Cs))\n",
    "n_Cs = len(Cs)\n",
    "n_classes = 9\n",
    "scores =  np.zeros((n_classes,n_Cs))\n",
    "\n",
    "for j in range(n_classes):\n",
    "        scores[j][:] = np.mean(lr_cv.scores_[j],axis = 0)\n",
    "    \n",
    "mse_mean = -np.mean(scores, axis = 0)\n",
    "pyplot.plot(np.log10(Cs), mse_mean.reshape(n_Cs,1)) \n",
    "#plt.plot(np.log10(reg.Cs)*np.ones(3), [0.28, 0.29, 0.30])\n",
    "pyplot.xlabel('log(C)')\n",
    "pyplot.ylabel('neg-logloss')\n",
    "pyplot.show()\n",
    "\n",
    "#print ('C is:',lr_cv.C_)  #对多类分类问题，每个类别的分类器有一个C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "Cs = [1, 10,100,1000]\n",
    "\n",
    "# 大量样本（6W+）、高维度（93），L2正则 --> 缺省用lbfgs\n",
    "# LogisticRegressionCV比GridSearchCV快\n",
    "lrcv_L2 = LogisticRegressionCV(Cs=Cs, cv = 5, scoring='neg_log_loss', penalty='l2', multi_class='ovr')\n",
    "lrcv_L2.fit(X_train, y_train)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrcv_L2.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dict with classes as the keys, and the values as the grid of scores obtained during cross-validating each fold,\n",
    "# Each dict value has shape (n_folds, len(Cs))\n",
    "n_Cs = len(Cs)\n",
    "n_classes = 9\n",
    "scores =  np.zeros((n_classes,n_Cs))\n",
    "\n",
    "for j in range(n_classes):\n",
    "        scores[j][:] = np.mean(lrcv_L2.scores_[j],axis = 0)\n",
    "    \n",
    "mse_mean = -np.mean(scores, axis = 0)\n",
    "pyplot.plot(np.log10(Cs), mse_mean.reshape(n_Cs,1)) \n",
    "#plt.plot(np.log10(reg.Cs)*np.ones(3), [0.28, 0.29, 0.30])\n",
    "pyplot.xlabel('log(C)')\n",
    "pyplot.ylabel('neg-logloss')\n",
    "pyplot.show()\n",
    "\n",
    "#print ('C is:',lr_cv.C_)  #对多类分类问题，每个类别的分类器有一个C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
